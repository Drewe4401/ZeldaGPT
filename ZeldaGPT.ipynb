{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8OVVvJQ4q4dlkqnjaTCMY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Drewe4401/ZeldaGPT/blob/main/ZeldaGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ZeldaGPT\n",
        "\n",
        "  * ZeldaGPT allows you to train a GPT model using the Zelda Text Dump Dataset. \n",
        "The program handles the data preprocessing, model configuration, and training process to optimize the language generation capabilities.\n",
        "  * Once the GPT model is trained, ZeldaGPT enables you to generate new text based on the trained model. This feature allows you to interact with the model and obtain Zelda-like dialogues, descriptions, or other text elements."
      ],
      "metadata": {
        "id": "8WTQsl88h1Yo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "* import torch: This imports the PyTorch library, which is an open-source machine learning library for Python, used for applications such as computer vision and natural language processing. It provides tensor computation with strong GPU acceleration, deep neural networks built on a tape-based autograd system, and a variety of optimization algorithms and tools for research and development.\n",
        "\n",
        "* import torch.nn as nn: This imports the neural network module from the PyTorch library and assigns it an alias nn. The torch.nn module provides classes and functions for creating and training neural networks. It contains classes for defining layers, loss functions, and optimization algorithms. By importing it as nn, it allows for easier and cleaner access to the neural network functionalities provided by the PyTorch library.\n"
      ],
      "metadata": {
        "id": "iYk65eBdhW9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "Xu0P6jfHgqU5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS4Gz_uXccdi",
        "outputId": "52cf9b80-6e53-4c8f-ba43-4cc728f4acd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-04 17:47:35--  https://raw.githubusercontent.com/Drewe4401/ZeldaGPT/main/zelda_text_dump.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 666033 (650K) [text/plain]\n",
            "Saving to: ‘zelda_text_dump.txt’\n",
            "\n",
            "\rzelda_text_dump.txt   0%[                    ]       0  --.-KB/s               \rzelda_text_dump.txt 100%[===================>] 650.42K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-05-04 17:47:35 (14.4 MB/s) - ‘zelda_text_dump.txt’ saved [666033/666033]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Drewe4401/ZeldaGPT/main/zelda_text_dump.txt #getting data set from github"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reading the file\n",
        "with open('zelda_text_dump.txt', 'r', encoding='utf-8') as f:\n",
        "  text = f.read()\n",
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9ZP4MT0c8dK",
        "outputId": "4a580a97-aa45-45c8-8c7f-553d4e412127"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  631587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500]) #Checking out the first 500 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6k86cjUdXKd",
        "outputId": "ec117778-56b2-4ad2-c3b0-1f2bf6598074"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You borrowed a Pocket Egg!\n",
            "A Pocket Cucco will hatch from\n",
            "it overnight. Be sure to give it\n",
            "back when you are done with it.\n",
            "\n",
            "You returned the Pocket Cucco\n",
            "and got Cojiro in return!\n",
            "Unlike other Cuccos, Cojiro\n",
            "rarely crows.\n",
            "\n",
            "You got an Odd Mushroom!\n",
            "A fresh mushroom like this is\n",
            "sure to spoil quickly! Take it to\n",
            "the Kakariko Potion Shop, quickly!\n",
            "\n",
            "You received an Odd Potion!\n",
            "It may be useful for something...\n",
            "Hurry to the Lost Woods!\n",
            "\n",
            "You returned the Odd Potion \n",
            "and got the Poacher's Saw!\n",
            "The youn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_in_text = sorted(list(set(text)))\n",
        "vocab_size = len(chars_in_text)\n",
        "print(''.join(chars_in_text))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSrdTdmbePFp",
        "outputId": "55b7c906-afeb-4ae9-ecb2-643bbebbe05b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u000b\f\u0010\u0014\u0015\u0016\u0017\u0018\u0019\u001b\u001c\u001d !\"&'()*+,-./0123456789:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZ^abcdefghijklmnopqrstuvwxyz|~§©´»ÁÄÈËÌÍÎÏÐÑÒÔÕ×ØÙÚÛÜÝÞßáâãäåæçèéôöùúûü†\n",
            "138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars_in_text) }\n",
        "itos = { i:ch for i,ch in enumerate(chars_in_text) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
      ],
      "metadata": {
        "id": "a3Zc0qNbgNh3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r97hWToZgmbJ",
        "outputId": "1cd98850-8b54-4d44-c613-8b00e6d9cd0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([631587]) torch.int64\n",
            "tensor([65, 82, 88, 13, 69, 82, 85, 85, 82, 90, 72, 71, 13, 68, 13, 56, 82, 70,\n",
            "        78, 72, 87, 13, 45, 74, 74, 14,  0, 41, 13, 56, 82, 70, 78, 72, 87, 13,\n",
            "        43, 88, 70, 70, 82, 13, 90, 76, 79, 79, 13, 75, 68, 87, 70, 75, 13, 73,\n",
            "        85, 82, 80,  0, 76, 87, 13, 82, 89, 72, 85, 81, 76, 74, 75, 87, 24, 13,\n",
            "        42, 72, 13, 86, 88, 85, 72, 13, 87, 82, 13, 74, 76, 89, 72, 13, 76, 87,\n",
            "         0, 69, 68, 70, 78, 13, 90, 75, 72, 81, 13, 92, 82, 88, 13, 68, 85, 72,\n",
            "        13, 71, 82, 81, 72, 13, 90, 76, 87, 75, 13, 76, 87, 24,  0,  0, 65, 82,\n",
            "        88, 13, 85, 72, 87, 88, 85, 81, 72, 71, 13, 87, 75, 72, 13, 56, 82, 70,\n",
            "        78, 72, 87, 13, 43, 88, 70, 70, 82,  0, 68, 81, 71, 13, 74, 82, 87, 13,\n",
            "        43, 82, 77, 76, 85, 82, 13, 76, 81, 13, 85, 72, 87, 88, 85, 81, 14,  0,\n",
            "        61, 81, 79, 76, 78, 72, 13, 82, 87, 75, 72, 85, 13, 43, 88, 70, 70, 82,\n",
            "        86, 22, 13, 43, 82, 77, 76, 85, 82,  0, 85, 68, 85, 72, 79, 92, 13, 70,\n",
            "        85, 82, 90, 86, 24,  0,  0, 65, 82, 88, 13, 74, 82, 87, 13, 68, 81, 13,\n",
            "        55, 71, 71, 13, 53, 88, 86, 75, 85, 82, 82, 80, 14,  0, 41, 13, 73, 85,\n",
            "        72, 86, 75, 13, 80, 88, 86, 75, 85, 82, 82, 80, 13, 79, 76, 78, 72, 13,\n",
            "        87, 75, 76, 86, 13, 76, 86,  0, 86, 88, 85, 72, 13, 87, 82, 13, 86, 83,\n",
            "        82, 76, 79, 13, 84, 88, 76, 70, 78, 79, 92, 14, 13, 60, 68, 78, 72, 13,\n",
            "        76, 87, 13, 87, 82,  0, 87, 75, 72, 13, 51, 68, 78, 68, 85, 76, 78, 82,\n",
            "        13, 56, 82, 87, 76, 82, 81, 13, 59, 75, 82, 83, 22, 13, 84, 88, 76, 70,\n",
            "        78, 79, 92, 14,  0,  0, 65, 82, 88, 13, 85, 72, 70, 72, 76, 89, 72, 71,\n",
            "        13, 68, 81, 13, 55, 71, 71, 13, 56, 82, 87, 76, 82, 81, 14,  0, 49, 87,\n",
            "        13, 80, 68, 92, 13, 69, 72, 13, 88, 86, 72, 73, 88, 79, 13, 73, 82, 85,\n",
            "        13, 86, 82, 80, 72, 87, 75, 76, 81, 74, 24, 24, 24,  0, 48, 88, 85, 85,\n",
            "        92, 13, 87, 82, 13, 87, 75, 72, 13, 52, 82, 86, 87, 13, 63, 82, 82, 71,\n",
            "        86, 14,  0,  0, 65, 82, 88, 13, 85, 72, 87, 88, 85, 81, 72, 71, 13, 87,\n",
            "        75, 72, 13, 55, 71, 71, 13, 56, 82, 87, 76, 82, 81, 13,  0, 68, 81, 71,\n",
            "        13, 74, 82, 87, 13, 87, 75, 72, 13, 56, 82, 68, 70, 75, 72, 85, 17, 86,\n",
            "        13, 59, 68, 90, 14,  0, 60, 75, 72, 13, 92, 82, 88, 81])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(.9*len(data))\n",
        "training_data = data[:n] # 90% of of text will be training data\n",
        "validation_data = data[n:] # 10% of text will be validation data"
      ],
      "metadata": {
        "id": "bNw0y4NX3Xie"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "print(training_data[:block_size+1])\n",
        "print(text[:9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49DCGW5C4qws",
        "outputId": "040055e8-27f0-4367-8a80-07100db5ab1f"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([65, 82, 88, 13, 69, 82, 85, 85, 82])\n",
            "You borro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 # Process this many parallel sequences\n",
        "torch.manual_seed(400)\n",
        "\n",
        "def get_batch(split):\n",
        "  data = training_data if split == 'train' else validation_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,)) # random block generation in a 4x8\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix]) # current integer\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix]) # next integer\n",
        "  return x, y\n",
        "\n",
        "x_batch, y_batch = get_batch('train')\n",
        "print('inputs:')\n",
        "print(x_batch.shape)\n",
        "print(x_batch)\n",
        "print('targets:')\n",
        "print(y_batch.shape)\n",
        "print(y_batch)\n",
        "\n",
        "print('-----------------------------------------------')\n",
        "\n",
        "for b in range(batch_size):\n",
        "  for t in range(block_size):\n",
        "    context = x_batch[b, :t+1]\n",
        "    target = y_batch[b, t]\n",
        "    print(f\"input {context.tolist()}, target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgfbooQr5Bbt",
        "outputId": "7138c221-2b26-4b2f-910a-f80282fe588f"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([32, 8])\n",
            "tensor([[71, 86, 13, 92, 82, 88, 13, 86],\n",
            "        [72, 79, 79, 13, 71, 82, 81, 72],\n",
            "        [ 0, 24, 24, 24, 24, 24, 24, 24],\n",
            "        [87, 75, 72, 80, 14,  0, 52, 82],\n",
            "        [82, 81, 72, 40, 14,  0,  0, 44],\n",
            "        [87, 82, 13, 59, 81, 82, 90, 75],\n",
            "        [13, 74, 82, 40,  0,  0, 29, 26],\n",
            "        [82, 80, 69, 86, 14,  0, 59, 72],\n",
            "        [80, 92, 13, 83, 85, 72, 70, 76],\n",
            "        [80, 72, 13, 68,  0, 80, 82, 81],\n",
            "        [13, 58, 88, 83, 72, 72, 86,  0],\n",
            "        [69, 82, 92, 13, 82, 73, 13, 80],\n",
            "        [87, 76, 80, 72,  0, 92, 82, 88],\n",
            "        [82, 85, 82, 81, 17, 86, 13, 58],\n",
            "        [73, 72, 81, 70, 72, 86, 13, 75],\n",
            "        [13, 68, 13, 80, 72, 80, 69, 72],\n",
            "        [82, 88, 74, 75, 13, 75, 72, 85],\n",
            "        [13, 59, 81, 82, 90, 75, 72, 68],\n",
            "        [92, 82, 88, 13, 70, 88, 87, 13],\n",
            "        [82, 13, 80, 72, 13, 88, 81, 87],\n",
            "        [85, 68, 76, 86, 72,  0, 80, 72],\n",
            "        [75, 68, 87, 13, 75, 82, 87, 13],\n",
            "        [90, 90, 90, 24, 24, 24,  0,  0],\n",
            "        [13, 68, 13, 86, 72, 79, 73, 23],\n",
            "        [40,  0, 55, 81, 70, 72, 13, 87],\n",
            "        [24, 24, 24,  0,  0, 65, 82, 88],\n",
            "        [89, 72, 13, 92, 82, 88, 13, 74],\n",
            "        [87, 75, 72, 13, 74, 82, 71, 71],\n",
            "        [13, 76, 87, 13, 72, 81, 71, 86],\n",
            "        [75, 72, 13, 44, 88, 81, 74, 72],\n",
            "        [71, 82, 81, 17, 87, 13, 72, 89],\n",
            "        [68, 81, 71, 13, 86, 70, 68, 85]])\n",
            "targets:\n",
            "torch.Size([32, 8])\n",
            "tensor([[86, 13, 92, 82, 88, 13, 86, 82],\n",
            "        [79, 79, 13, 71, 82, 81, 72, 22],\n",
            "        [24, 24, 24, 24, 24, 24, 24, 24],\n",
            "        [75, 72, 80, 14,  0, 52, 82, 82],\n",
            "        [81, 72, 40, 14,  0,  0, 44, 82],\n",
            "        [82, 13, 59, 81, 82, 90, 75, 72],\n",
            "        [74, 82, 40,  0,  0, 29, 26, 33],\n",
            "        [80, 69, 86, 14,  0, 59, 72, 87],\n",
            "        [92, 13, 83, 85, 72, 70, 76, 82],\n",
            "        [72, 13, 68,  0, 80, 82, 81, 86],\n",
            "        [58, 88, 83, 72, 72, 86,  0,  0],\n",
            "        [82, 92, 13, 82, 73, 13, 80, 88],\n",
            "        [76, 80, 72,  0, 92, 82, 88, 13],\n",
            "        [85, 82, 81, 17, 86, 13, 58, 88],\n",
            "        [72, 81, 70, 72, 86, 13, 75, 72],\n",
            "        [68, 13, 80, 72, 80, 69, 72, 85],\n",
            "        [88, 74, 75, 13, 75, 72, 85, 72],\n",
            "        [59, 81, 82, 90, 75, 72, 68, 71],\n",
            "        [82, 88, 13, 70, 88, 87, 13, 87],\n",
            "        [13, 80, 72, 13, 88, 81, 87, 76],\n",
            "        [68, 76, 86, 72,  0, 80, 72, 13],\n",
            "        [68, 87, 13, 75, 82, 87, 13, 86],\n",
            "        [90, 90, 24, 24, 24,  0,  0, 55],\n",
            "        [68, 13, 86, 72, 79, 73, 23, 83],\n",
            "        [ 0, 55, 81, 70, 72, 13, 87, 75],\n",
            "        [24, 24,  0,  0, 65, 82, 88, 13],\n",
            "        [72, 13, 92, 82, 88, 13, 74, 82],\n",
            "        [75, 72, 13, 74, 82, 71, 71, 72],\n",
            "        [76, 87, 13, 72, 81, 71, 86, 13],\n",
            "        [72, 13, 44, 88, 81, 74, 72, 82],\n",
            "        [82, 81, 17, 87, 13, 72, 89, 72],\n",
            "        [81, 71, 13, 86, 70, 68, 85, 92]])\n",
            "-----------------------------------------------\n",
            "input [71], target: 86\n",
            "input [71, 86], target: 13\n",
            "input [71, 86, 13], target: 92\n",
            "input [71, 86, 13, 92], target: 82\n",
            "input [71, 86, 13, 92, 82], target: 88\n",
            "input [71, 86, 13, 92, 82, 88], target: 13\n",
            "input [71, 86, 13, 92, 82, 88, 13], target: 86\n",
            "input [71, 86, 13, 92, 82, 88, 13, 86], target: 82\n",
            "input [72], target: 79\n",
            "input [72, 79], target: 79\n",
            "input [72, 79, 79], target: 13\n",
            "input [72, 79, 79, 13], target: 71\n",
            "input [72, 79, 79, 13, 71], target: 82\n",
            "input [72, 79, 79, 13, 71, 82], target: 81\n",
            "input [72, 79, 79, 13, 71, 82, 81], target: 72\n",
            "input [72, 79, 79, 13, 71, 82, 81, 72], target: 22\n",
            "input [0], target: 24\n",
            "input [0, 24], target: 24\n",
            "input [0, 24, 24], target: 24\n",
            "input [0, 24, 24, 24], target: 24\n",
            "input [0, 24, 24, 24, 24], target: 24\n",
            "input [0, 24, 24, 24, 24, 24], target: 24\n",
            "input [0, 24, 24, 24, 24, 24, 24], target: 24\n",
            "input [0, 24, 24, 24, 24, 24, 24, 24], target: 24\n",
            "input [87], target: 75\n",
            "input [87, 75], target: 72\n",
            "input [87, 75, 72], target: 80\n",
            "input [87, 75, 72, 80], target: 14\n",
            "input [87, 75, 72, 80, 14], target: 0\n",
            "input [87, 75, 72, 80, 14, 0], target: 52\n",
            "input [87, 75, 72, 80, 14, 0, 52], target: 82\n",
            "input [87, 75, 72, 80, 14, 0, 52, 82], target: 82\n",
            "input [82], target: 81\n",
            "input [82, 81], target: 72\n",
            "input [82, 81, 72], target: 40\n",
            "input [82, 81, 72, 40], target: 14\n",
            "input [82, 81, 72, 40, 14], target: 0\n",
            "input [82, 81, 72, 40, 14, 0], target: 0\n",
            "input [82, 81, 72, 40, 14, 0, 0], target: 44\n",
            "input [82, 81, 72, 40, 14, 0, 0, 44], target: 82\n",
            "input [87], target: 82\n",
            "input [87, 82], target: 13\n",
            "input [87, 82, 13], target: 59\n",
            "input [87, 82, 13, 59], target: 81\n",
            "input [87, 82, 13, 59, 81], target: 82\n",
            "input [87, 82, 13, 59, 81, 82], target: 90\n",
            "input [87, 82, 13, 59, 81, 82, 90], target: 75\n",
            "input [87, 82, 13, 59, 81, 82, 90, 75], target: 72\n",
            "input [13], target: 74\n",
            "input [13, 74], target: 82\n",
            "input [13, 74, 82], target: 40\n",
            "input [13, 74, 82, 40], target: 0\n",
            "input [13, 74, 82, 40, 0], target: 0\n",
            "input [13, 74, 82, 40, 0, 0], target: 29\n",
            "input [13, 74, 82, 40, 0, 0, 29], target: 26\n",
            "input [13, 74, 82, 40, 0, 0, 29, 26], target: 33\n",
            "input [82], target: 80\n",
            "input [82, 80], target: 69\n",
            "input [82, 80, 69], target: 86\n",
            "input [82, 80, 69, 86], target: 14\n",
            "input [82, 80, 69, 86, 14], target: 0\n",
            "input [82, 80, 69, 86, 14, 0], target: 59\n",
            "input [82, 80, 69, 86, 14, 0, 59], target: 72\n",
            "input [82, 80, 69, 86, 14, 0, 59, 72], target: 87\n",
            "input [80], target: 92\n",
            "input [80, 92], target: 13\n",
            "input [80, 92, 13], target: 83\n",
            "input [80, 92, 13, 83], target: 85\n",
            "input [80, 92, 13, 83, 85], target: 72\n",
            "input [80, 92, 13, 83, 85, 72], target: 70\n",
            "input [80, 92, 13, 83, 85, 72, 70], target: 76\n",
            "input [80, 92, 13, 83, 85, 72, 70, 76], target: 82\n",
            "input [80], target: 72\n",
            "input [80, 72], target: 13\n",
            "input [80, 72, 13], target: 68\n",
            "input [80, 72, 13, 68], target: 0\n",
            "input [80, 72, 13, 68, 0], target: 80\n",
            "input [80, 72, 13, 68, 0, 80], target: 82\n",
            "input [80, 72, 13, 68, 0, 80, 82], target: 81\n",
            "input [80, 72, 13, 68, 0, 80, 82, 81], target: 86\n",
            "input [13], target: 58\n",
            "input [13, 58], target: 88\n",
            "input [13, 58, 88], target: 83\n",
            "input [13, 58, 88, 83], target: 72\n",
            "input [13, 58, 88, 83, 72], target: 72\n",
            "input [13, 58, 88, 83, 72, 72], target: 86\n",
            "input [13, 58, 88, 83, 72, 72, 86], target: 0\n",
            "input [13, 58, 88, 83, 72, 72, 86, 0], target: 0\n",
            "input [69], target: 82\n",
            "input [69, 82], target: 92\n",
            "input [69, 82, 92], target: 13\n",
            "input [69, 82, 92, 13], target: 82\n",
            "input [69, 82, 92, 13, 82], target: 73\n",
            "input [69, 82, 92, 13, 82, 73], target: 13\n",
            "input [69, 82, 92, 13, 82, 73, 13], target: 80\n",
            "input [69, 82, 92, 13, 82, 73, 13, 80], target: 88\n",
            "input [87], target: 76\n",
            "input [87, 76], target: 80\n",
            "input [87, 76, 80], target: 72\n",
            "input [87, 76, 80, 72], target: 0\n",
            "input [87, 76, 80, 72, 0], target: 92\n",
            "input [87, 76, 80, 72, 0, 92], target: 82\n",
            "input [87, 76, 80, 72, 0, 92, 82], target: 88\n",
            "input [87, 76, 80, 72, 0, 92, 82, 88], target: 13\n",
            "input [82], target: 85\n",
            "input [82, 85], target: 82\n",
            "input [82, 85, 82], target: 81\n",
            "input [82, 85, 82, 81], target: 17\n",
            "input [82, 85, 82, 81, 17], target: 86\n",
            "input [82, 85, 82, 81, 17, 86], target: 13\n",
            "input [82, 85, 82, 81, 17, 86, 13], target: 58\n",
            "input [82, 85, 82, 81, 17, 86, 13, 58], target: 88\n",
            "input [73], target: 72\n",
            "input [73, 72], target: 81\n",
            "input [73, 72, 81], target: 70\n",
            "input [73, 72, 81, 70], target: 72\n",
            "input [73, 72, 81, 70, 72], target: 86\n",
            "input [73, 72, 81, 70, 72, 86], target: 13\n",
            "input [73, 72, 81, 70, 72, 86, 13], target: 75\n",
            "input [73, 72, 81, 70, 72, 86, 13, 75], target: 72\n",
            "input [13], target: 68\n",
            "input [13, 68], target: 13\n",
            "input [13, 68, 13], target: 80\n",
            "input [13, 68, 13, 80], target: 72\n",
            "input [13, 68, 13, 80, 72], target: 80\n",
            "input [13, 68, 13, 80, 72, 80], target: 69\n",
            "input [13, 68, 13, 80, 72, 80, 69], target: 72\n",
            "input [13, 68, 13, 80, 72, 80, 69, 72], target: 85\n",
            "input [82], target: 88\n",
            "input [82, 88], target: 74\n",
            "input [82, 88, 74], target: 75\n",
            "input [82, 88, 74, 75], target: 13\n",
            "input [82, 88, 74, 75, 13], target: 75\n",
            "input [82, 88, 74, 75, 13, 75], target: 72\n",
            "input [82, 88, 74, 75, 13, 75, 72], target: 85\n",
            "input [82, 88, 74, 75, 13, 75, 72, 85], target: 72\n",
            "input [13], target: 59\n",
            "input [13, 59], target: 81\n",
            "input [13, 59, 81], target: 82\n",
            "input [13, 59, 81, 82], target: 90\n",
            "input [13, 59, 81, 82, 90], target: 75\n",
            "input [13, 59, 81, 82, 90, 75], target: 72\n",
            "input [13, 59, 81, 82, 90, 75, 72], target: 68\n",
            "input [13, 59, 81, 82, 90, 75, 72, 68], target: 71\n",
            "input [92], target: 82\n",
            "input [92, 82], target: 88\n",
            "input [92, 82, 88], target: 13\n",
            "input [92, 82, 88, 13], target: 70\n",
            "input [92, 82, 88, 13, 70], target: 88\n",
            "input [92, 82, 88, 13, 70, 88], target: 87\n",
            "input [92, 82, 88, 13, 70, 88, 87], target: 13\n",
            "input [92, 82, 88, 13, 70, 88, 87, 13], target: 87\n",
            "input [82], target: 13\n",
            "input [82, 13], target: 80\n",
            "input [82, 13, 80], target: 72\n",
            "input [82, 13, 80, 72], target: 13\n",
            "input [82, 13, 80, 72, 13], target: 88\n",
            "input [82, 13, 80, 72, 13, 88], target: 81\n",
            "input [82, 13, 80, 72, 13, 88, 81], target: 87\n",
            "input [82, 13, 80, 72, 13, 88, 81, 87], target: 76\n",
            "input [85], target: 68\n",
            "input [85, 68], target: 76\n",
            "input [85, 68, 76], target: 86\n",
            "input [85, 68, 76, 86], target: 72\n",
            "input [85, 68, 76, 86, 72], target: 0\n",
            "input [85, 68, 76, 86, 72, 0], target: 80\n",
            "input [85, 68, 76, 86, 72, 0, 80], target: 72\n",
            "input [85, 68, 76, 86, 72, 0, 80, 72], target: 13\n",
            "input [75], target: 68\n",
            "input [75, 68], target: 87\n",
            "input [75, 68, 87], target: 13\n",
            "input [75, 68, 87, 13], target: 75\n",
            "input [75, 68, 87, 13, 75], target: 82\n",
            "input [75, 68, 87, 13, 75, 82], target: 87\n",
            "input [75, 68, 87, 13, 75, 82, 87], target: 13\n",
            "input [75, 68, 87, 13, 75, 82, 87, 13], target: 86\n",
            "input [90], target: 90\n",
            "input [90, 90], target: 90\n",
            "input [90, 90, 90], target: 24\n",
            "input [90, 90, 90, 24], target: 24\n",
            "input [90, 90, 90, 24, 24], target: 24\n",
            "input [90, 90, 90, 24, 24, 24], target: 0\n",
            "input [90, 90, 90, 24, 24, 24, 0], target: 0\n",
            "input [90, 90, 90, 24, 24, 24, 0, 0], target: 55\n",
            "input [13], target: 68\n",
            "input [13, 68], target: 13\n",
            "input [13, 68, 13], target: 86\n",
            "input [13, 68, 13, 86], target: 72\n",
            "input [13, 68, 13, 86, 72], target: 79\n",
            "input [13, 68, 13, 86, 72, 79], target: 73\n",
            "input [13, 68, 13, 86, 72, 79, 73], target: 23\n",
            "input [13, 68, 13, 86, 72, 79, 73, 23], target: 83\n",
            "input [40], target: 0\n",
            "input [40, 0], target: 55\n",
            "input [40, 0, 55], target: 81\n",
            "input [40, 0, 55, 81], target: 70\n",
            "input [40, 0, 55, 81, 70], target: 72\n",
            "input [40, 0, 55, 81, 70, 72], target: 13\n",
            "input [40, 0, 55, 81, 70, 72, 13], target: 87\n",
            "input [40, 0, 55, 81, 70, 72, 13, 87], target: 75\n",
            "input [24], target: 24\n",
            "input [24, 24], target: 24\n",
            "input [24, 24, 24], target: 0\n",
            "input [24, 24, 24, 0], target: 0\n",
            "input [24, 24, 24, 0, 0], target: 65\n",
            "input [24, 24, 24, 0, 0, 65], target: 82\n",
            "input [24, 24, 24, 0, 0, 65, 82], target: 88\n",
            "input [24, 24, 24, 0, 0, 65, 82, 88], target: 13\n",
            "input [89], target: 72\n",
            "input [89, 72], target: 13\n",
            "input [89, 72, 13], target: 92\n",
            "input [89, 72, 13, 92], target: 82\n",
            "input [89, 72, 13, 92, 82], target: 88\n",
            "input [89, 72, 13, 92, 82, 88], target: 13\n",
            "input [89, 72, 13, 92, 82, 88, 13], target: 74\n",
            "input [89, 72, 13, 92, 82, 88, 13, 74], target: 82\n",
            "input [87], target: 75\n",
            "input [87, 75], target: 72\n",
            "input [87, 75, 72], target: 13\n",
            "input [87, 75, 72, 13], target: 74\n",
            "input [87, 75, 72, 13, 74], target: 82\n",
            "input [87, 75, 72, 13, 74, 82], target: 71\n",
            "input [87, 75, 72, 13, 74, 82, 71], target: 71\n",
            "input [87, 75, 72, 13, 74, 82, 71, 71], target: 72\n",
            "input [13], target: 76\n",
            "input [13, 76], target: 87\n",
            "input [13, 76, 87], target: 13\n",
            "input [13, 76, 87, 13], target: 72\n",
            "input [13, 76, 87, 13, 72], target: 81\n",
            "input [13, 76, 87, 13, 72, 81], target: 71\n",
            "input [13, 76, 87, 13, 72, 81, 71], target: 86\n",
            "input [13, 76, 87, 13, 72, 81, 71, 86], target: 13\n",
            "input [75], target: 72\n",
            "input [75, 72], target: 13\n",
            "input [75, 72, 13], target: 44\n",
            "input [75, 72, 13, 44], target: 88\n",
            "input [75, 72, 13, 44, 88], target: 81\n",
            "input [75, 72, 13, 44, 88, 81], target: 74\n",
            "input [75, 72, 13, 44, 88, 81, 74], target: 72\n",
            "input [75, 72, 13, 44, 88, 81, 74, 72], target: 82\n",
            "input [71], target: 82\n",
            "input [71, 82], target: 81\n",
            "input [71, 82, 81], target: 17\n",
            "input [71, 82, 81, 17], target: 87\n",
            "input [71, 82, 81, 17, 87], target: 13\n",
            "input [71, 82, 81, 17, 87, 13], target: 72\n",
            "input [71, 82, 81, 17, 87, 13, 72], target: 89\n",
            "input [71, 82, 81, 17, 87, 13, 72, 89], target: 72\n",
            "input [68], target: 81\n",
            "input [68, 81], target: 71\n",
            "input [68, 81, 71], target: 13\n",
            "input [68, 81, 71, 13], target: 86\n",
            "input [68, 81, 71, 13, 86], target: 70\n",
            "input [68, 81, 71, 13, 86, 70], target: 68\n",
            "input [68, 81, 71, 13, 86, 70, 68], target: 85\n",
            "input [68, 81, 71, 13, 86, 70, 68, 85], target: 92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the BigramLanguageModel class, which inherits from the PyTorch nn.Module class\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    # Initialize the BigramLanguageModel class\n",
        "    def __init__(self, vocab_size):\n",
        "        # Call the parent class constructor\n",
        "        super(BigramLanguageModel, self).__init__()\n",
        "        # Create an embedding layer with vocab_size input and output dimensions\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    # Define the forward pass for the model\n",
        "    def forward(self, idx, targets=None):\n",
        "        # Calculate the logits by passing the input idx through the embedding layer\n",
        "        logits = self.token_embedding_table(idx)  # (B, T, C) (batch_size, block_size, vocab_size)\n",
        "\n",
        "        # If there are no targets, set the loss to None\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            # If there are targets, reshape the logits and targets for the loss calculation\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            # Calculate the cross-entropy loss between logits and targets\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        # Return both logits and loss\n",
        "        return logits, loss\n",
        "\n",
        "    # Define the generate function for generating text\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # Loop for the specified number of tokens to generate\n",
        "        for _ in range(max_new_tokens):\n",
        "            # Calculate the logits and loss\n",
        "            logits, loss = self(idx)\n",
        "            # Take the last token logits and calculate the softmax probabilities\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            # Sample the next token index based on the probabilities\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            # Concatenate the sampled token index with the existing indices\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        # Return the generated token indices\n",
        "        return idx\n",
        "\n",
        "# Instantiate the BigramLanguageModel with vocab_size\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "# Perform the forward pass on a batch of input data (x_batch) and targets (y_batch)\n",
        "logits, loss = m(x_batch, y_batch)\n",
        "\n",
        "# Print the shape of the logits tensor and the calculated loss\n",
        "print(logits.shape)\n",
        "print(loss)  # loss should be -ln(1/138) = 4.927\n",
        "\n",
        "# Generate text by calling the generate function and print the decoded text\n",
        "print(decode(m.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arzZ5FAM66X2",
        "outputId": "2fba5a00-17b6-45aa-a411-d085da98f33d"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 138])\n",
            "tensor(5.4830, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "ö68j?&Qu0rp&0Bg6ûÔW~\u0018z\u0017ÞgoLMsÔCY|ØknßÌÕÚdÏwã\f\u0019EXGGk\u001cVo|KsÕÈ\u0019fÎ\u0010Î\u00189DáçsO3â1/4VÎôfyfd6\"B:×<!y/Ð>5Î2oMß\u001båy\u0016QHl/\fÄ9\u0010»4Íx\u000by*(Lmm»Dv\fiÍ,ÛÔÎ2´Svôèq§9b\f?Fwè\u001bvFXZFcKËÚ'a\u0014E|T(×Aèw×o!q,ãd\fËS©lãec\n",
            "\u001d\u0018:vgh´RC!K\u0015wJxv\u0019\u001cÞË\u0017\u001dÈm§0DLrUMÈ8jãú\u000byp\u001cKÍå?çäS\"ÏH\u0015)5.ÜüZÙ'*ÜH*è\"j×~ãæfLéÝSÐ+ù7é4éúhKa\u0014NèÑ)gÝs3sZ\u0018+Ø´LWúÎÎ†åÚèÑYtbÞ69T\u0016ÜJ\u001c§ÏÜ0ÚhJT\"Ï;ÞÚB\u0017åHD|\u0010r&t7éè9QKÜgoãl\u001bu^»\u0018ÔÚy^ôÕ*dl,<F~ÛÔb)\u0018^ä-yÏ\u001crÄ2>ÕtLäNOút†~AüÝå?ÌÕGß´I98Ø\f\u0015\u0014!W|BPnJA§mh\u001cK1ã*|ÒIvzzô×sAqÔ^\u0018ÝöIB\u000bûYyÜfI6\n",
            "\u001dömHoT-sU'1FÛSÔ\u001dÐÔ\n",
            "HOÝtöKnXåspúw\u0010Ë\u001cfYA'DÈÞÄ8ÒNûC(ËËS\u0010ß+u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an optimizer for the model 'm'\n",
        "# Use the AdamW optimization algorithm with a learning rate of 1e-3 (0.001)\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "ZeerfewYd-h3"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop for 10,000 steps (iterations) in the training process\n",
        "for steps in range(10000):\n",
        "    # Get a batch of training data (input and target) using the get_batch function\n",
        "    x_batch, y_batch = get_batch('train')\n",
        "    \n",
        "    # Perform the forward pass on the input batch (x_batch) and target batch (y_batch)\n",
        "    # and get the output logits and the loss\n",
        "    logits, loss = m(x_batch, y_batch)\n",
        "    \n",
        "    # Reset the gradients in the optimizer before calculating new gradients\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    \n",
        "    # Perform the backward pass to calculate gradients with respect to the loss\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update the model's parameters (weights and biases) using the calculated gradients\n",
        "    optimizer.step()\n",
        "\n",
        "# Print the final value of the loss for the last iteration\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNmJax6DeJaH",
        "outputId": "a0d9fc85-6081-4ff7-bd52-830546d5379a"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4902431964874268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a sequence of tokens using the trained model 'm'\n",
        "# Pass an initial input tensor of zeros with a shape of (1, 1) and dtype 'long'\n",
        "# Set the number of tokens to generate to 500\n",
        "generated_sequence = m.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)\n",
        "\n",
        "# Convert the generated token tensor to a list of token IDs\n",
        "generated_token_ids = generated_sequence[0].tolist()\n",
        "\n",
        "# Decode the list of token IDs into human-readable text using the 'decode' function\n",
        "decoded_text = decode(generated_token_ids)\n",
        "\n",
        "# Print the decoded text\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6KXJz6EfJqE",
        "outputId": "dbacbb2a-cd63-4c54-eefc-f052a974168a"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Thintou yind.\n",
            "\n",
            "bthe\u001d\u001couy tored preno\n",
            "g We ou tetre..\n",
            "(ZVderpu areekNoud k m re thains whe mim\n",
            "I'ly ashe ck ofon t Ï^mayo|Ango.\n",
            "yonkitthet?\n",
            "o\n",
            "Sur hililet rof\n",
            "SThe?\"âEAnd, ce andous\n",
            "Ik fu, alartt st itheroour k!\n",
            "Ong|-§f I's deery! ig ry?\n",
            "yontis ghinouffomot 4n DU.Ý\f) tak bre prenggon\n",
            "the thhe t d!\n",
            "acheman\n",
            "an thekste hal an Yof o yonelliropa ttoupl t s we t.\n",
            "r rid wathetofl, nge whang!Îly\n",
            "O\n",
            "be agy ithinor ott otowhtisked s d\n",
            "\n",
            "\n",
            "C) f Yo tinas cat the f...*´Eatou tht \n",
            "\n",
            "ce hos thoow*»§ôËpitabAris w....\n"
          ]
        }
      ]
    }
  ]
}